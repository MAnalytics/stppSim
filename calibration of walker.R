library(rgdal)
library(rgl)
library(sp)
library(rgeos)
library(raster)
#library(shapefiles)
install.packages("plot3D")
library(plot3D)


polysf<-st_as_sf(poly)

st_coordinates(polysf)



getwd()
setwd("C:/Users/monsu/Documents/GitHub/stppSim backup")
install.packages("SiMRiv")


#to determine the number generated by adjusting the transitionmatrix

prob <- seq(0.01, 1, 0.01)

all_prob <- NULL

for (j in 1:length(prob)){ #j<-1

all <- NULL

  for(i in 1:1000){ #i<-1
    LevyWalker <- species(
      state.RW() + state.CRW(0.99),
      transitionMatrix(prob[j], 0.70)) #THIS MATRIX...0.82

    #for daily
    step_length <- 24 #meaning 1-step/hrs

    LevyWalker <- (LevyWalker + step_length) * s_threshold

    sim <- simulate(LevyWalker, 200) #200 numberof points
    nrow(sim)
    length(which(sim[,3]==1))
    sim[which(sim[,3]==1),]
    all <- c(all, length(which(sim[,3]==1)))
  }
  # plot(sim, type="l", asp=1)
  all_prob <- c(all_prob, median(all))
  hist(all)
  flush.console()
  print(paste(prob[j], median(all), sep= "|"))
}

all_prob_ <- cbind(prob, all_prob)



a_0.70 <- data.frame(cbind(0.70, all_prob_)) #%>%
  #dplyr::select()

plot(a_0.70$prob, a_0.70$all_prob)


#fit a regression

#fit the model (#ref: https://www.statology.org/power-regression-in-r/)
model <- lm(log(all_prob)~ log(prob), data=a_0.70)

model2 <- lm(log(prob)~ log(all_prob), data=a_0.70)

#view the output of the model
summary(model2)
#library(SiMRiv)

ln(y) = 4.91373 + 0.76944*ln(x) #model1

ln(x) = -6.25679 + 1.26863*ln(y)#mode 2

#Applying e to both sides, we can rewrite the equation as:

all_prob = exp(4.91373 + 0.76944*ln(prob))

prob = exp(-6.25679 + 1.26863*ln(all_prob))

#relationship between x and y
#-----------------------------
exp(-6.25679 + 1.26863*log(y)) #input in psim
#-----------------------------


#-----------------------
prob = nthroot(abs(90 - 136.1463), 1.3)
#-----------------------

(74 - 136.1463)^1.3


#136.1463 * 0.03^0.76944

#library(pracma)
To calculate the nth root:

> 8^(1/3)
[1] 2
> exp(log(8)/3)
[1] 2
nthroot(64, 4)





exp(0.15333)

ln(2)
log(2)


s_thres <- c(0, 1000)
#1-day band temporal neighbourhooods
t_thres <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,
             31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60)

#--
#create a table to hold the result

result_Table <- matrix(0, (length(t_thres)-1), (length(s_thres)-1))

#colnames of the table
col_N <- NULL
for(g in 2:length(s_thres)){ #g<-2
  col_N <-c(col_N, paste(s_thres[g-1],"-",s_thres[g],sep=""))
}

#rownames of the table
row_N <- NULL
for(g in 2:length(t_thres)){ #g<-2
  row_N <-c(row_N, paste(t_thres[g-1],"-",t_thres[g],sep=""))
}
colnames(result_Table) <- col_N
rownames(result_Table) <- row_N

#-------------------------------------------------
setwd("C:/Users/monsu/Desktop/shapefile/")
#road_Network <- readOGR(dsn=".", "utm_shp") #in projected coordinate system..


#--------------------------------------------
#offender's origin
#offenders_Origin <- readOGR(dsn=".", "all_landuse_UTM")

offenders_Origin <- readOGR(dsn="C:/Users/monsu/Documents/backFlashDrive_25012018/shapefile", "all_landuse_SS_UTM")
head(offenders_Origin@data)
unique(offenders_Origin@data$col_ID)

colPallete<-c("green","blue","yellow","grey")
landuseColors <- colPallete[offenders_Origin$col_ID]
plot(offenders_Origin, col=landuseColors)
leg.txt <-c("l1", "l2", "l3", "l4")
legend("right",   # location of legend
       legend=unique(offenders_Origin$col_ID), # categories or elements to render in
       # the legend
       fill=colPallete) # color pa

#extract coord list of residential buildings names(offenders_Origin)
res_SF_Det <- offenders_Origin[which(offenders_Origin$col_ID==1),]
res_SF_Det <- cbind(res_SF_Det$ID, as.data.frame(res_SF_Det$x), as.data.frame(res_SF_Det$y))
colnames(res_SF_Det) <-  c("ID","x","y")

res_SF_Att <- offenders_Origin[which(offenders_Origin$col_ID==2),]
res_SF_Att <- cbind(res_SF_Att$ID, as.data.frame(res_SF_Att$x), as.data.frame(res_SF_Att$y))
colnames(res_SF_Att) <-  c("ID","x","y")

res_MF <- offenders_Origin[which(offenders_Origin$col_ID==3),]
res_MF <- cbind(res_MF$ID, as.data.frame(res_MF$x), as.data.frame(res_MF$y))
colnames(res_MF) <-  c("ID","x","y")

#--------------------------------------------
#import the road shapefile
#road_Network <- readOGR(dsn=".", "utm_shp") #in projected coordinate system..plot(road_Network)

road_Network <- readOGR(dsn="C:/Users/monsu/Documents/backFlashDrive_25012018/shapefile", "utm_SS_shp") #in projected coordinate system..plot(road_Network)
plot(road_Network)

head(road_Network@data)
#prob_def <- c(0, 0.0001, 0.001, 0.01, 1)  #p<-1


###final_Offender_Attr <- list()


#undo this
landuse_map <- resistanceFromShape(road_Network, res = 5,
                                   buffer=15, background = 0.95, margin = 10)
####for(p in 1:length(prob_def)){#999999999999999999999 p<-1
plot(landuse_map)

offender_Info <- list()


#specify number of offenders to simulate
n_walkers <- 300


offenders_Origin_cood <- sample(c(1,2,3), size=n_walkers, replace=TRUE, prob=c(0.05,0.15,0.8))


#number of days (Note: may use no of days from the background pattern simulated)
start_Date <- as.Date("2015-01-01")

step_length <- 20

p_range <- 1000

n_days <- 365

#n_days <- 730


#visualise the landuse image
plot(landuse_map, axes=F)

#---------------------------------------------
get_Value<-NULL
get_Value[1:(length(t_thres)-1)] <- list(c(0)) #
#---------------------------------------------------



#for(id in 1:300){#999999999999999
for(id in 1:n_walkers){##123 # id <- 1

  #Create the landuse information from the road network
  #Using the road network, two-class landuse map ('paths' and 'others') is created.
  #Set the prob. of 'background = 0.95' in order to restrict offenders' to road network only.
  #The road is also buffered to allow easy movement of the offender
  #Set the resolution ('res' = (buffer size/3))

  #---------------------------------
  #set a random initial x, y coordinate for the offender
  #init = xyFromCell(landuse_map, sample(which(values(landuse_map) == 0), 1))

  #randomly select the starting coods of the offender if lives in residential category 1
  if(offenders_Origin_cood[id]==1){#1
    init <- matrix(as.matrix(res_SF_Det[sample(1:nrow(res_SF_Det), size=1, replace=TRUE),2:3]),,2)

  }#1

  #randomly select the starting coods of the offender if lives in residential category 2
  if(offenders_Origin_cood[id]==2){#1
    init <- matrix(as.matrix(res_SF_Att[sample(1:nrow(res_SF_Att), size=1, replace=TRUE),2:3]),,2)

  }#1

  #randomly select the starting coods of the offender if lives in residential category 3
  if(offenders_Origin_cood[id]==3){#1
    init <- matrix(as.matrix(res_MF[sample(1:nrow(res_MF), size=1, replace=TRUE),2:3]),,2)
  }#1

  #Define a three-state movement behaviour for the offender,
  #State 1: "Exploring"
  #State 2: "Exploring but motivated"
  #State 3: "Offending" (correlation probability of 0.98)

  #prob_def <- c(0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001)
  #prob_def <- c(0.1, 0.2, 0.3, 0.4, 0.5) # p<-3

  #simulat.. the frequency dis.. of time
  ##for

  #---------------------------------------------------
  #t_thres <- c(0, 7, 14, 21, 28, 35, 42, 49, 56)
  #t_thres <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30)


  #get_Value<-NULL
  #get_Value[1:(length(t_thres)-1)] <- list(c(0)) #
  #---------------------------------------------------

  the_Count <- NULL


  # all <- NULL
  # for(i in 1:10000){
  #   LevyWalker <- species(
  #     state.RW() + state.CRW(0.99),
  #     transitionMatrix(0.005, 0.02))
  #
  #   #for daily
  #   step_length <- 24 #meaning 1-step/hrs
  #
  #   LevyWalker <- (LevyWalker + step_length) * s_threshold
  #
  #   sim <- simulate(LevyWalker, 200) #200
  #   nrow(sim)
  #   all <- c(all, length(which(sim[,3]==1)))
  # }
  # plot(sim, type="l", asp=1)
  # sd(all)
  # hist(all)
  #
  #



  #for(loopp in 1:1000){#999999999999999

  ##for(id in 1:300){#999999999999999

  levy.walker <- species(state.RW() + state.RW() + state.CRW(0.98),

                         #for the 300 simulations
                         #----------------------------
                         #trans = transitionMatrix(0.5, 0.0001, 0.5, 0.022, 0.5, 0.05)) ##0-7...1000 iterations #2199 (#adjust 0.0065 for sizes..)
                         #trans = transitionMatrix(0.5, 0.0001, 0.5, 0.041, 0.5, 0.5)) #evenly distributed..#2180
                         #trans = transitionMatrix(0.5, 0.0001, 0.5, 0.003, 0.5, 0.5)) #;aaa<-c(1,2); bbb<-c(sample(28:31, 1))#heavy to the left..
                         trans = transitionMatrix(0.5, 0.0001, 0.5, 0.028, 0.5, 0.5)) #2164 WITH....
  #aaa<-c(1,2,3,4)#number of crimes to create #crime_T <- 20 #
  #bbb<-c(sample(1:3, 1,prob=c(0.3,0.2,0.1)), sample(13:16,1,prob=c(0.2,0.3,0.3,0.2)),
  #sample(28:31, 1,prob=c(0.2,0.3,0.3,0.2)),sample(43:46, 1,prob=c(0.2,0.3,0.3,0.2)),
  #sample(58:60, 1,prob=c(0.1,0.2,0.3)))

  #Perceptual range of 1000m; step length of 10m with each step corresponding to each day of the year.
  levy.walker <- (levy.walker + step_length) * p_range

  #crime committed per day

  crimes_Committed <- NULL

  #simulate movement #750 * 10 = 7.5km covered in two hours in two days.
  sim.lw.road <- simulate(levy.walker, 365,
                          resist = landuse_map, coords = init)

  #combine the date of occurence  mode(sim.lw.road)
  sim.lw.road <- cbind(sim.lw.road, as.data.frame(start_Date))
  colnames(sim.lw.road) <- c("x", "y", "state", "date")

  sim.lw.road[,4] <- sim.lw.road[,4] + (1:length(sim.lw.road[,4])-1)


  #SECTION ###1010
  #####################################
  #----------------------------
  #additional codes to add long-term events
  aaa<-c(1,2,3,4)#number of crimes to create #crime_T <- 20 #
  #aaa<-c(1,2)

  crime_T <- sample(aaa, 1, replace=TRUE)

  index_Counter <- 0
  for(hh in 1: crime_T){#hh<-1
    if(hh==1){
      init_V <- sample(1:60, 1) #make 1st entry
      index_Counter <- index_Counter + init_V
      sim.lw.road[index_Counter,3] <- 2
    }
    if(hh!=1){
      bbb<-c(sample(1:3, 1,prob=c(0.3,0.2,0.1)), sample(13:16,1,prob=c(0.2,0.3,0.3,0.2)),
             sample(28:31, 1,prob=c(0.2,0.3,0.3,0.2)),sample(43:46, 1,prob=c(0.2,0.3,0.3,0.2)),
             sample(58:60, 1,prob=c(0.1,0.2,0.3)))
      #bbb<-c(sample(28:31, 1))
      init_V <- sample(bbb, 1, replace=TRUE)
      index_Counter <- index_Counter + init_V
      if(index_Counter<=n_days){#0909
        sim.lw.road[index_Counter,3]<-2
      }#0909
    }
  }#hh
  #----------------------------
  #####################################


  #the below or the above..#ALTERNATE BETWEEN SECTION ###1010
  ######################################
  ###crimes_details <- sim.lw.road[which(sim.lw.road[,3]==2),]
  ######################################

  if(nrow(crimes_details)>=1){#4545
    crimes_details <- sim.lw.road[which(sim.lw.road[,3]==2),]

    #bind the walker ID
    crimes_details <- cbind(crimes_details, id)  #id<-1

    crimes_Committed <- rbind(crimes_Committed, crimes_details)
    #sim.lw.road

    flush.console()
    print(k)
    ###}#33
    crimes_Committed

    the_Count <- c(the_Count, nrow(crimes_Committed))

  }#4545
  ###############################################################
  ###############################################################
  ###############################################################
  ###############################################################!is.null(crimes_details)#!is.null(crimes_Committed)

  #if(nrow(crimes_Committed)>=1){ h###   ###CHANGE THIS!!

  if(!is.null(crimes_Committed)){ h###
    #--------------------------------------------
    #t_thres <- c(0, 7, 14, 21, 28, 35, 42, 49, 56)
    #t_thres <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30)
    #-------

    dat1 <- which(crimes_Committed$date > "2015-02-28")
    dat2 <- which(crimes_Committed$date < "2015-11-01")

    data_N <- crimes_Committed[intersect(dat1, dat2),]

    ####the_Indices <- which(!rownames(crimes_Committed)%in%rownames(data_N))

    ###time <- crimes_Committed$date#

    ###n <- length(time)
    #create a matrix to store the result
    ###tdis<-matrix(0,n,n)

    ###for (i in 1:n){
    ###for (j in 1:n){
    ### tdis[i,j]<- abs( time[i] - time[j])
    ###}
    ###}

    ###tdis[lower.tri(tdis)] <- 1000000
    ###diag(tdis) <- 1000000

    ###colnames(tdis) <- as.character(c(time))

    #get_Value<-NULL
    #get_Value[1:(length(t_thres)-1)] <- list(c(0)) #

    ###at2 <- tdis #dim(at)

    ###for(tt in 2:length(t_thres)){## tt<-8
    ###at2 <- tdis #dim(at)
    ###at2[which(tdis <=(t_thres[tt-1]))] <-0
    ###at2[which(tdis>t_thres[tt]) ] <-0
    ###at2[which(at2!=0)] <- 1
    ###diag(at2) <- 0
    #percentage relative to the total number generated..
    #s12 <- (sum(at2)/n)*100
    ###s12 <- (sum(at2))
    ###get_Value[tt-1] <- list(c(get_Value[[tt-1]], s12))

    ###}##

  }###h
  flush.console()
  print(id)


  #####}#99999999999999999


  #-----------------------------------------------
  ###############################################################
  ###############################################################
  ###############################################################
  ###############################################################


  offender_ID <- id
  offender_init_Coord <- init
  combine_Result <- list(offender_ID, offender_init_Coord, crimes_Committed)
  offender_Info[id] <- list(combine_Result)

  flush.console()
  print(id)



}##123
#----------------------------------------------
#----------------------------------------------
#----------------------------------------------




#offender_Info[[1]]

all_crimes <- NULL
for(j in 1:length(offender_Info)){#j<-1
  crimes <- offender_Info[[j]][[3]]
  n_row <- nrow(crimes)
  if(!is.null(n_row)){
    #if(n_row!=0){
    crimes_ID <- offender_Info[[j]][[1]]
    all_crimes <- rbind(all_crimes, crimes)
  }
}#

#final_Offender_Attr[p] <- list(all_crimes)

final_Offender_Attr <- list(all_crimes)

flush.console()
print(id)


###}#99999999999999999999999999999999




################################################################################
################################################################################
################################################################################
#THIS MAY NOT WORK WELL AGAIN ... SINCE I NOW USE SECTION: ##UU##UU##
##histt_mean <- NULL
##histt_sd <- NULL
##for(y in 1:length(get_Value)){#y<-1
##histt_mean <- c(histt_mean, mean(get_Value[[y]]))
##histt_sd <- c(histt_sd, sd(get_Value[[y]]))
##}

#----------------------------
##prof_freq <- histt_mean
#----------------------------

##mmm <- max(prof_freq)
##par(mar=c(7,7,4,2)+0.2, mgp=c(5,1,1))
##dev.new()
##plot(c(0,length(rownames(result_Table))), c(0,(mmm)), xlab="", ylab="", main=" ",
##cex=0.001, col="white", cex.lab=1.5, cex.axis=1.5, cex.main=1.5, las=1, xaxt = 'n')

##for(i in 1:length(prof_freq)){ #i<-1
##segments((i), 0, (i), prof_freq[i], lwd=6, lend=2)
##}
##abline(h=(-0.05), col="black")
##axis(1, at=1:length(rownames(result_Table)), labels=rownames(result_Table))

##total_Crime <- sum(the_Count)
#hist(the_Count)

################################################################################
################################################################################
################################################################################

########################################################################p<-1

par(mfrow=c(5,2))


plot(road_Network,col="grey")

##for(h in 1:length(final_Offender_Attr)){ #h<-1

h<-1

next_Plot <- final_Offender_Attr[[h]]           #nrow(next_Plot)

n_row <- nrow(next_Plot)
if(n_row!=0){#
  #convert the crimes' x,y coords to shapefile
  crimes_shape <- SpatialPointsDataFrame(next_Plot[,1:2], next_Plot, proj4string = coord_Sys)  #X_shape@data
  plot(crimes_shape, col = "black", pch=16, add=TRUE)

}#

crimes_shape


crimes_shape

}

###write.table(next_Plot, file="synthetic_Data_forthnight_600.csv", sep=",")

######
#100 offenders:
offenders_100 #<- final_Offender_Attr

offenders_200 #<- final_Offender_Attr

######################################################################################
######################################################################################
######################################################################################
######################################################################################
######################################################################################
######################################################################################
######################################################################################
######################################################################################
#for frequency distribution

SECTION: ###UU##UU##


  #100 metre interval spatial neighbourhooods
  s_thres <- c(0, 1000)
#1-day band temporal neighbourhooods
t_thres <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,
             31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60)

#--------------------------------------------------------------
#create a table to hold the result
#--------------------------------------------------------------
result_Table <- matrix(0, (length(t_thres)-1), (length(s_thres)-1))

#colnames of the table
col_N <- NULL
for(g in 2:length(s_thres)){ #g<-2
  col_N <-c(col_N, paste(s_thres[g-1],"-",s_thres[g],sep=""))
}

#rownames of the table
row_N <- NULL
for(g in 2:length(t_thres)){ #g<-2
  row_N <-c(row_N, paste(t_thres[g-1],"-",t_thres[g],sep=""))
}
colnames(result_Table) <- col_N
rownames(result_Table) <- row_N


get_Value <- NULL
#----------------------------------------------
get_Value[1:(length(t_thres)-1)] <- list(c(0)) #
#----------------------------------------------


#############################
#FOR REAL DATA
real_Crime <- read.table(file="chicago_2015_dataset.csv", sep=",", head=TRUE)
data <-cbind(real_Crime$x, real_Crime$y, (as.numeric(real_Crime$date)))
colnames(data)<-c("x","y","t")
dat <-as.data.frame(data)
head(dat)


#############################
#FOR SIMULATED DATA

h<-1
synt_Crime <- final_Offender_Attr[[h]]
data <-cbind(synt_Crime$x, synt_Crime$y, (as.numeric(synt_Crime$date)-16435))
colnames(data)<-c("x","y","t")
dat <-as.data.frame(data)
head(dat)

#qqq <- as.numeric(as.Date("2015-01-01"))-16435

#dat <- dat[10:20,]

#dat<- dat[order(dat[,3]),] #head(dat)#mode(dat)
########################-----------------------------------------

b<-s_thres[ss-1]
c<-s_thres[ss]

d<-t_thres[tt-1]
e<-t_thres[tt]

#getting the start time for the entire process
Start.time <- Sys.time()


#-------------------------------------
#function to calculate the pairwise spatial distance
#-------------------------------------
#variable to store the distance
take_dist <- NULL

for(w in 1:nrow(dat)){#w<-1
  M <- cbind(dat$x[w],dat$y[w], dat$x,dat$y)
  dist_cal <- apply(M, 1, function(x)  sqrt((x[1]-x[3])^2 + (x[2]-x[4])^2) )
  take_dist <- rbind(take_dist,dist_cal)
}

#changing it to a matrix
sdis <- matrix(take_dist, ,nrow(dat))

#changing the lower part of the distance matrix to a very large number, so that they don't count in the calculation
sdis[lower.tri(sdis)] <- 1000000
diag(sdis) <- 1000000


#--------------------------------------------------------


#####################
profile_freq <- NULL

for(ss in 2:length(s_thres)){ #ss=2

  #-------------------------------------
  #to calculate the pairwise temporal distance matrix
  #-------------------------------------
  #######################


  time <- dat$t  #
  n <- length(time)
  #create a matrix to store the result
  tdis<-matrix(0,n,n)

  for (i in 1:n){
    for (j in 1:n){
      tdis[i,j]<- abs( time[i] - time[j])
    }
  }

  #changing the lower part of the temporal matrix to a large number so that they don't count
  tdis[lower.tri(tdis)] <- 1000000
  diag(tdis) <- 1000000


  #set the number of replications to use for pvalue calculation

  Nrep<-1
  ktmon<-1:(Nrep+1)
  as<-matrix(0,nrow(sdis),nrow(sdis))

  as<-sdis
  as[which(sdis<=s_thres[ss-1]) ] <-0
  as[which(sdis>s_thres[ss]) ] <-0
  as[which(as!=0)] <- 1

  diag(as) <- 0  #
  #This code calculates the freq. at varying temporal distance for a given spatial distance
  #------------------------------------------

  #at2 <- tdis #dim(at)

  #t_thres <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30)
  #------
  #----------------------------------------------
  #get_Value <- NULL
  #get_Value[1:(length(t_thres)-1)] <- list(c(0)) #
  #----------------------------------------------


  for(kk in 2:length(t_thres)){## kk<-2
    as2 <- as  #dim(as)
    at2 <- tdis #dim(at)  at2[1] 1e+00 * 0 time
    at2[which(tdis <=(t_thres[kk-1]))] <-0   #at2[1]
    at2[which(tdis > t_thres[kk]) ] <-0
    #at2[which(tdis>2)] <-0
    at2[which(at2!=0)] <- 1   #sum(at2) 2100*2100
    diag(as2) <- 0
    diag(at2) <- 0

    #-------------------------------------------------------#can block this out..to use absolute count
    #normalising the temporal counts to account for edge effect
    #-------------------------------------------
    copy_at2 <- at2 #duplicate of at2
    copy_at2[lower.tri(at2)]<-"na"

    ###at2[,(length(t_thres)-kk+2):length(t_thres)]<-0
    at2[,(length(t_thres)-kk+2):length(t_thres)]<-0
    copy_at2[,(length(t_thres)-kk+2):length(t_thres)]<-"na"
    diag(copy_at2)<-"na"
    n <- length(which(copy_at2!="na")) #total number of eligible cells.
    #-------------------------------------------------------#can block this out..to use absolute count

    #copy_at2
    #-------------------------------------------
    s12 <- (sum(as2*at2)/n)*100  #normalising
    #s12 <- sum(as2*at2)
    get_Value[kk-1] <- list(c(get_Value[[kk-1]], s12))

    #------------------------------------------

    flush.console()
    print(kk)

  } ##close temporal


  profile_freq[ss-1] <- list(get_Value)
  names(profile_freq)[ss-1]<-paste(colnames(result_Table)[ss-1],"metres")

} #close spatial


#the result
print(result_Table)



############################################


histt_mean <- NULL
histt_sd <- NULL
for(y in 1:length(get_Value)){#y<-1
  histt_mean <- c(histt_mean, mean(get_Value[[y]]))
  histt_sd <- c(histt_sd, sd(get_Value[[y]]))
}

#----------------------------
prof_freq <- histt_mean
#prof_freq <- histt_sd
#----------------------------

mmm <- max(prof_freq)
par(mar=c(7,7,4,2)+0.2, mgp=c(5,1,1))
dev.new()
plot(c(0,length(rownames(result_Table))), c(0,(mmm+0.0)), xlab="", ylab="", main=" ",
     cex=0.001, col="white", cex.lab=1.5, cex.axis=1.5, cex.main=1.5, las=1, xaxt = 'n')

for(i in 1:length(prof_freq)){ #i<-1
  segments((i), 0, (i), prof_freq[i], lwd=6, lend=2)
}
abline(h=(-0.05), col="black")
axis(1, at=1:length(rownames(result_Table)), labels=rownames(result_Table))

total_Crime <- sum(the_Count)
#hist(the_Count)

################################################################################
################################################################################
################################################################################

########################################################################p<-1

par(mfrow=c(5,2))


plot(road_Network,col="grey")

##for(h in 1:length(final_Offender_Attr)){ #h<-1

h<-1

next_Plot <- final_Offender_Attr[[h]]

n_row <- nrow(next_Plot)
if(n_row!=0){#
  #convert the crimes' x,y coords to shapefile
  crimes_shape <- SpatialPointsDataFrame(next_Plot[,1:2], next_Plot, proj4string = coord_Sys)  #X_shape@data
  plot(crimes_shape, col = "black", pch=16, add=TRUE)

}#

crimes_shape

#write.table(next_Plot, file="synthetic_cyclic_1000m.csv", sep=",")

#write.table(next_Plot, file="synthetic_high_short_interval_1000m.csv", sep=",")

#write.table(next_Plot, file="synthetic_Random_T_clustering_1000m.csv", sep=",")




####################################
#SPATIAL CLUSTERING TESTS
#https://rdrr.io/cran/spatstat/man/Kest.html
#K-test with edge effect correction.


library(spatstat)

# Plot the data in ggplot
library(rgdal)
library(sp)

#import boundary data
spbdry <- readOGR(dsn = ".", "boundary_SS_UTM")  # boundary layer
sproads <- readOGR(dsn = ".", "utm_SS_shp")  # road layer

# Coerce all the data to data.frames for ggplot
W <- owin(poly = spbdry@polygons[[1]]@Polygons[[1]]@coords[seq(from = 3840, to = 1,
                                                               by = -1), ])
#
plot(W)
plot(sproads, col="grey", add=TRUE)


#import point data #head(real_Crime)
real_Crime <- read.table(file="chicago_2015_dataset.csv", sep=",", head=TRUE)
dat <- ppp(x = real_Crime$x, y = real_Crime$y, window = W)
#
plot(dat, add=TRUE, pch=16, cex=1, col="black")

homogeneious

#FOR REAL DATA
#repeat the sigma values all through..
#----------------------------------------

sigma_Value <- c(200, 400, 600, 800, 1000)
dev.new()
par(mfcol=c(5,1))
par(mar=c(0.5, 4.5, 0.5, 0.5))

for(i in 1:length(sigma_Value)){#111 i<-1

  real_Crime <- read.table(file="chicago_2015_dataset.csv", sep=",", head=TRUE)
  dat <- ppp(x = real_Crime$x, y = real_Crime$y, window = W)


  #if(v==1){
  Ken <- envelope(dat, Kest, nsim=99, r = r_V, correction="trans")
  plot(Ken, xaxt="n", main="", legend=FALSE)
  axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
  #}

  #if(v!=1){
  #Ken <- envelope(dat, Kest, nsim=9, r = r_V, correction="trans")
  #plot(Ken, xaxt="n", main=" ", legend=FALSE)
  #axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
  #}

  flush.console()
  print(paste("real_Data_", sigma_Value[i], sep="___"))


}#111
#---------------------------------


homogeneious

#FOR SYNTHETIC DATA
#use the sigma value of each dataset.
#----------------------------------------
#for homogeneous plot
library(spatstat)

#for homogeneous plot
dev.new()
par(mfcol=c(5,3)) #par(mfcol=c(1,1))
par(mar=c(0.5, 4.5, 0.5, 0.5))


sigma_Value <- c(200, 400, 600, 800, 1000)
pattern_List <- c("synthetic_cyclic_", "synthetic_high_short_interval_", "synthetic_Random_T_clustering_")
r_V <- c(0, 200, 400, 600, 800, 1000, 1200)

for(v in 1:length(pattern_List)){#22  #v<-1
  for(i in 1:length(sigma_Value)){#111 i<-1

    #import point data #head(real_Crime)
    syn_Crime <- read.table(file=paste(pattern_List[v],sigma_Value[i],"m.csv",sep=""), sep=",", head=TRUE)
    dat <- ppp(x = syn_Crime$x, y = syn_Crime$y, window = W)

    if(v==1){
      Ken <- envelope(dat, Kest, nsim=99, r = r_V, correction="trans")
      plot(Ken, xaxt="n", main="", legend=FALSE)
      axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
    }

    if(v!=1){
      Ken <- envelope(dat, Kest, nsim=99, r = r_V, correction="trans")
      plot(Ken, xaxt="n", main=" ", legend=FALSE, ylab="")
      axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
    }

  }#111
  flush.console()
  print(paste(pattern_List[v], sigma_Value[i], sep="___"))
}#22
#----------------------------------------



#############################################################################################
Inhomogeneious
#FOR REAL DATA
#repeat the sigma values all through..
#----------------------------------------

sigma_Value <- c(200, 400, 600, 800, 1000)
r_V <- c(0, 200, 400, 600, 800, 1000, 1200)
dev.new()
par(mfcol=c(5,1))
par(mar=c(0.5, 4.5, 0.5, 0.5))

for(i in 1:length(sigma_Value)){#111 i<-1

  real_Crime <- read.table(file="chicago_2015_dataset.csv", sep=",", head=TRUE)
  dat <- ppp(x = real_Crime$x, y = real_Crime$y, window = W)

  smo <- density.ppp(dat, sigma=sigma_Value[i])
  Ken <- envelope(dat, Kinhom, nsim=99,
                  simulate=expression(rpoispp(smo)),
                  sigma=sigma_Value[i], r = r_V, correction="trans")

  plot(Ken, xaxt="n", main="", legend=FALSE)
  axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)

  flush.console()
  print(paste("real_Data_", sigma_Value[i], sep="___"))

}#111
#---------------------------------

################################################################################


synthetic

#for inhomogeneous plot


sigma_Value <- c(200, 400, 600, 800, 1000)
pattern_List <- c("synthetic_cyclic_", "synthetic_high_short_interval_", "synthetic_Random_T_clustering_")
r_V <- c(0, 200, 400, 600, 800, 1000, 1200)

#for homogeneous plot
dev.new()
par(mfcol=c(5,3)) #par(mfcol=c(1,1))
par(mar=c(0.5, 4.5, 0.5, 0.5))

for(v in 1:length(pattern_List)){#22  #v<-1
  for(i in 1:length(sigma_Value)){#111 i<-1
    #import point data #head(real_Crime)
    syn_Crime <- read.table(file=paste(pattern_List[v],sigma_Value[i],"m.csv",sep=""), sep=",", head=TRUE)
    dat <- ppp(x = syn_Crime$x, y = syn_Crime$y, window = W)


    if(v==1){
      smo <- density.ppp(dat, sigma=sigma_Value[i])
      Ken <- envelope(dat, Kinhom, nsim=99,
                      simulate=expression(rpoispp(smo)),
                      sigma=sigma_Value[i], r = r_V, correction="trans")

      plot(Ken, xaxt="n", main="", legend=FALSE)
      axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
    }

    if(v!=1){
      smo <- density.ppp(dat, sigma=sigma_Value[i])
      Ken <- envelope(dat, Kinhom, nsim=99,
                      simulate=expression(rpoispp(smo)),
                      sigma=sigma_Value[i], r = r_V, correction="trans")

      plot(Ken, xaxt="n", main="", legend=FALSE, ylab="")
      axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
    }



  }#111
  flush.console()
  print(paste(pattern_List[v], sigma_Value[i], sep="___"))
}#22
#----------------------------------------









#### SPATIOTEMPORAL INTERACTION TEST:
#USING PAIR CORRELATION FUNCTION
#fit a non-seperable model when there is strong spatiotemporal autocorrelation (meaning space-time
are not seperable --- my interpretation based on https://stats.stackexchange.com/questions/184482/interpreting-spatio-temporal-variograms))

#------------------------------------------

##########################################################
##########################################################


#for inhomogeneous plot (RUNNING IT FOR JUST ONE BANDWIDTH VALUE)
library(spatstat)
sigma_Value <- c(200, 400, 600, 800, 1000)
pattern_List <- c("synthetic_cyclic_")

r_V <- c(0, 200, 400, 600, 800, 1000, 1200)
line_T <- c(3,4,2,5,1)

for(v in 1:length(pattern_List)){#22  #v<-1

  #import point data #head(real_Crime)
  #syn_Crime <- read.table(file=paste(pattern_List[v],sigma_Value[i],"m.csv",sep=""), sep=",", head=TRUE)
  syn_Crime <- read.table(file=paste(pattern_List[v],800,"m.csv",sep=""), sep=",", head=TRUE)
  dat <- ppp(x = syn_Crime$x, y = syn_Crime$y, window = W)

  for(i in 1:length(sigma_Value)){#111 i<-1

    if(i==1){
      dev.new()
      smo <- density.ppp(dat, 800)
      Ken <- envelope(dat, Kinhom, nsim=99,
                      simulate=expression(rpoispp(smo)),
                      sigma=sigma_Value[i], r = r_V, correction="trans")
      plot(Ken, main=paste(pattern_List[v],"_sim.800_",sigma_Value[i],"m.csv",sep=""), lty=3)
    }

    if(i>1){#i<-5
      dev.new()
      Ken <- Kest(dat, sigma=sigma_Value[i], correction="trans", r=r_V)
      plot(Ken, main=paste(pattern_List[v],"_sim.800_",sigma_Value[i],"m.csv",sep=""), lty=3)
      #plot(Ken2, lty=line_T[i], add=TRUE, col=c("black","NA"))

    }


  }#111
  flush.console()
  print(paste(pattern_List[v], sigma_Value[i], sep="___"))
}#22
#----------------------------------------

color=c("blue","green")

plot(Ken, col=alpha(color, 0.5))

length(Ken)

.~r col = alpha(cols, 0.5),

x <- c(1:5)
color <- c(2,2,3,4,5)
color_transparent <- adjustcolor(color, alpha.f = c(0.1, 0.4))

plot(x, col = color, pch = 20, cex = 4)
plot(x, col = color_transparent, pch = 20, cex = 4)




#### SPATIOTEMPORAL INTERACTION TEST:
#USING PAIR CORRELATION FUNCTION
#fit a non-seperable model when there is strong spatiotemporal autocorrelation (meaning space-time
are not seperable --- my interpretation based on https://stats.stackexchange.com/questions/184482/interpreting-spatio-temporal-variograms))

#------------------------------------------


#SPATIAL DISTRIBUTION OF SIMULATED DATASETS



road_Network <- readOGR(dsn=".", "utm_SS_shp") #in projected coordinate system..plot(road_Network)
plot(road_Network)


setwd("E:/shapefile/")

plot(road_Network,col="grey")

##for(h in 1:length(final_Offender_Attr)){ #h<-1

h<-1

next_Plot <- final_Offender_Attr[[h]]           #nrow(next_Plot)

n_row <- nrow(next_Plot)
if(n_row!=0){#
  #convert the crimes' x,y coords to shapefile
  crimes_shape <- SpatialPointsDataFrame(next_Plot[,1:2], next_Plot, proj4string = coord_Sys)  #X_shape@data
  plot(crimes_shape, col = "black", pch=16, add=TRUE)

}#

crimes_shape

sigma_Value <- c(200, 400, 600, 800, 1000)
pattern_List <- c("synthetic_cyclic_", "synthetic_high_short_interval_", "synthetic_Random_T_clustering_")
r_V <- c(0, 200, 400, 600, 800, 1000, 1200)

#for homogeneous plot
dev.new()
par(mfcol=c(5,3)) #par(mfcol=c(1,1))
par(mar=c(0.5, 4.5, 0.5, 0.5))

for(v in 1:length(pattern_List)){#22  #v<-1
  for(i in 1:length(sigma_Value)){#111 i<-1
    #import point data #head(real_Crime)
    syn_Crime <- read.table(file=paste(pattern_List[v],sigma_Value[i],"m.csv",sep=""), sep=",", head=TRUE)
    #dat <- ppp(x = syn_Crime$x, y = syn_Crime$y, window = W)

    crimes_shape <- SpatialPointsDataFrame(syn_Crime[,1:2], syn_Crime, proj4string = coord_Sys)  #X_shape@data
    plot(crimes_shape, col = "black", pch=16)
    plot(road_Network,col="grey", , add=TRUE)

  }

}

if(v==1){
  smo <- density.ppp(dat, sigma=sigma_Value[i])
  Ken <- envelope(dat, Kinhom, nsim=99,
                  simulate=expression(rpoispp(smo)),
                  sigma=sigma_Value[i], r = r_V, correction="trans")

  plot(Ken, xaxt="n", main="", legend=FALSE)
  axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
}

if(v!=1){
  smo <- density.ppp(dat, sigma=sigma_Value[i])
  Ken <- envelope(dat, Kinhom, nsim=99,
                  simulate=expression(rpoispp(smo)),
                  sigma=sigma_Value[i], r = r_V, correction="trans")

  plot(Ken, xaxt="n", main="", legend=FALSE, ylab="")
  axis(side = 1, at = r_V, labels = FALSE, tck = -0.03)
}



}#111
flush.console()
print(paste(pattern_List[v], sigma_Value[i], sep="___"))
}#22
#----------------------------------------


#########################################################################
#########################################################################
#########################################################################
#########################################################################
#########################################################################
#########################################################################


dev.new()

real_Crime <- read.table(file="chicago_2015_dataset.csv", sep=",", head=TRUE)
dat <- ppp(x = real_Crime$x, y = real_Crime$y, window = W)

smo <- density.ppp(dat, sigma=sigma_Value[i])


#########################################################################

syn_Crime <- read.table(file=paste(pattern_List[v],800,"m.csv",sep=""), sep=",", head=TRUE)
dat <- ppp(x = syn_Crime$x, y = syn_Crime$y, window = W)

smo <- density.ppp(dat, sigma=sigma_Value[i])














for (kkk in 1:length(crime_types)){ ##############0000000000000000000000000 kkk<-1


  #SELECT THE CRIME OF INTEREST

  data_CUT <-  data[which(data$Primary_Ty==crime_types[kkk]),]

  #ADD THE EXTENT DATA...

  #PREDICTION WITH KDE
  ##############################
  #########

  #PREPARING DATA TO PREDICT

  #-------------------------------------------------
  data_CUT_train <- cbind(data_CUT[,1],data_CUT[,4], data_CUT[,15], data_CUT[,16], data_CUT[,8])
  colnames(data_CUT_train)<- c("SN","COUNT","X","Y","T")
  #-------------------------------------------------


  ## Create a density surface based on the locations of the points.
  ##This uses the sm.density function in the sm package.

  #DATABASE OF PREDICTION

  #camden..
  ##data_Base<-seq(1, 961, 1) #413 no of grids..

  #data_Base<-seq(1, 961, 1) #413 no of grids..



  ##Load the Camden grid shapefile.

  #grids<- readShapePoly("gridsSS.shp")  ###take up

  grids<- readShapePoly("gridsSS_150_project.shp")  ###take up

  data_Base<-seq(1, length(grids), 1) #413 no of grids..

  #--------------------------------------
  grids_0 <- readOGR(dsn=".", layer="spatial_grid_system_50") #UTM

  #-------------------------------
  crime_Type <- c("ASSAULT","BURGLARY","MOTOR")
  #-------------------------------



  #Total_time_length<-397 #overall number of days in a year


  #-------------------------------------------
  Start_Training <- 40816  #21/12/2011  40814
  #-------------------------------------------

  #-------------------------------------------
  back_in_TIME  <- Start_Training  - 90
  #-------------------------------------------

  #steps<-2      #days to predict

  #r<-1
  ###LOOPING THE PREDICTIONS
  #specify how many predictions


  #KDE_RANKING <- NULL
  final_Risk <- NULL
  this_Result <- list()


  collate_TIME2 <- list()


  #tm<-0
  for (tm in 0: 97){              #500000000000000000000000000000000000000000000000##---------------------

    #for (tm in 0: 3){              #500000000000000000000000000000000000000000000000##---------------------



    ###Date_to_train_until <- Date_to_train_until + tm

    #start time
    start.time <- Sys.time()


    #-----------------------
    ab <- proc.time()
    #-----------------------


    #subset the needed records from the 'data'
    dataPoints1<-(which(data_CUT_train[,5] <= back_in_TIME + tm))

    dataPoints2<-(which(data_CUT_train[,5] <= Start_Training + tm))

    # 3 weeks data
    training_dataset <- data_CUT_train[setdiff(dataPoints2, dataPoints1),]

    #the training dataset
    dataPoints<-training_dataset

    #-------------------------------
    #append the current date

    max_Time <- max(dataPoints[,5])

    #-------------------------------

    #additional points to add
    thematrix<-matrix(0, 4,  5)


    #for camden....
    #------------------------------------------------------------------
    #add extrapoint to extend the kernel beyond the grids.... max time value added for subsetting
    #left
    thematrix[1,1]<-90000
    thematrix[1,2]<-1
    thematrix[1,3]<-444450
    thematrix[1,4]<-4628450
    thematrix[1,5]<-max_Time

    #top
    thematrix[2,1]<-90001
    thematrix[2,2]<-1
    thematrix[2,3]<-447360
    thematrix[2,4]<-4634235
    thematrix[2,5]<-max_Time

    #right
    thematrix[3,1]<-90002
    thematrix[3,2]<-1
    thematrix[3,3]<-455644
    thematrix[3,4]<-4625567
    thematrix[3,5]<-max_Time

    #bottom
    thematrix[4,1]<-90003
    thematrix[4,2]<-1
    thematrix[4,3]<-450708
    thematrix[4,4]<-4621662
    thematrix[4,5]<-max_Time
    #----------------------------------------------------------------------


    thematrix<-as.data.frame(thematrix)
    colnames(thematrix)<-c("SN", "COUNT", "X", "Y", "T")

    dataPoints<-rbind(dataPoints, thematrix)

    ## Plot the XY coordinates (do not close the plot window).

    ## Plot lon to see what it looks like in......

    #COMPUTING OPTIMAL BANDWIDTH OF X- AND Y- DIMENSIONS
    #calculating the bandwidth for the x-dimension
    summary(dataPoints$X)
    std_X<-sd(dataPoints$X)
    data_lengthX<-length(dataPoints$X)
    quantile3<-quantile(dataPoints$X, 0.75)
    quantile1<-quantile(dataPoints$X, 0.25)
    A<-min(std_X, ((quantile3 - quantile1)/1.349))
    bandWidthX <- (0.9 * A * (data_lengthX ^(-1/5)))   #bandwidth of X


    #calculating the bandwidth for the y-dimension
    summary(dataPoints$Y)
    std_Y<-sd(dataPoints$Y)
    data_lengthY<-length(dataPoints$Y)
    quantile3<-quantile(dataPoints$Y, 0.75)
    quantile1<-quantile(dataPoints$Y, 0.25)
    A<-min(std_Y, ((quantile3 - quantile1)/1.349))
    bandWidthY <- (0.9 * A * (data_lengthY^(-1/5)))   #bandwidth of Y

    #the vector of bandwidth
    bandWidthXY<-as.vector(cbind(bandWidthX, bandWidthY))

    #THE KERNEL DENSITY ESTIMATION
    #r<-1
    ##if (r==1){
    #open a device for plot
    #dev.new();
    #kernelPlot = dev.cur()
    #device 1
    ##plot(dataPoints$X, dataPoints$Y);
    ##plot(grids, add=T, lwd=1)
    ##}

    #dev.set(kernelPlot)

    #dataPoints_den <- sm.density(data.frame(dataPoints$X, dataPoints$Y), weights=head(dataPoints)$COUNT, h=bandWidthXY,
    #display= "image", ngrid=100)    #VERIFY WHAT ngrid is!!                             #..................................................

    dataPoints_den <- sm.density(data.frame(dataPoints$X, dataPoints$Y), weights=head(dataPoints)$COUNT, h=bandWidthXY, ngrid=100)    #VERIFY WHAT ngrid is!!

    #dim(dataPoints_den)
    #dataPoints_den <- sm.density(data.frame(dataPoints$X, dataPoints$Y), weights=head(dataPoints)$COUNT,
    #h=bandWidthXY, ngrid=100)    #VERIFY WHAT ngrid is!!


    #if(r>1){
    ## add the points and City of London boundary for context
    #dev.set(kernerPlot); points(dataPoints$X, dataPoints$Y, pch=23, cex=0.3)


    ## We can convert the 'dataPoints_den' output into a spatial grid for further spatial analysis.
    temp=SpatialPoints(expand.grid(x=dataPoints_den$eval.points[,1], y=dataPoints_den$eval.points[,2]))

    temp = SpatialPixelsDataFrame(temp, data.frame(kde = array(dataPoints_den$estimate,
                                                               length(dataPoints_den$estimate))))

    #create matrix to hold sum of density value for all grids
    den_grid_Sum <- matrix(0, nrow(grids), 2)

    ##LOOP THROUGH EACH GRID and sum up all density value inside it.
    #i<-1

    #plot(temp)
    #plot(grids[1,],add=TRUE)
    #plot(grids[i,], add=TRUE)
    ## cookie-cut the density estimation to only include the chosen grid.
    #sel=!is.na(overlay(temp, grids[i,]))

    ##sel <- temp %over% grids[i,]


    sel <- temp %over% grids  #length(temp)  names(grids$id)[[1]]

    sel <- cbind(sel, (1:nrow(sel)))
    sel <- sel[which(sel[,1]!="NA"),]

    clipped_grid = temp[sel[,2],]   #clipped_grid[[1]]  nrow(sel) #names(clipped_grid)
    sel <- cbind(sel, clipped_grid$kde)
    unique_sel <- unique(sel[,1])

    for(i in 1:length(unique_sel)){ #### i<-1   max(unique_sel)

      den_Value <- sum(sel[which(sel[,1]==unique_sel[i]),3])

      den_grid_Sum[i,1]<- unique_sel[i]
      den_grid_Sum[i,2]<- den_Value

    }####

    #PLOTTING THE KERNEL DENSITY
    #rank grids based on prediction
    #sort each grid in descending order of density value

    den_grid_Sum <- den_grid_Sum[order(-den_grid_Sum[,2]),]

    #write.table(den_grid_Sum, file="risknew.csv", sep=",")
    #-------------------------
    final_risk_Value <- den_grid_Sum
    #--------------------------

    time.taken2 <- proc.time() - ab


    #start time
    end.time <- Sys.time()
    time.taken <- end.time - start.time

    collate_TIME2[tm+1] <- as.numeric(time.taken2)[2]
    #--------------------------------------------------

    #KDE_RANKING <- cbind(KDE_RANKING, den_grid_Sum[,1])


    #total distance...names(xxLine)  #names(grids)

    t_dist <- length(grids)

    match_grids <-  grids[match(final_risk_Value[,1], grids$id),]

    dist_mat <-  match_grids$id

    #risk <- 1:length(dist_mat)

    cumSum_dist = 1:length(grids)

    in_Perc <- (cumSum_dist/t_dist)*100

    total_d <- in_Perc[length(in_Perc)]

    #comb_result[1065,]
    num10 <- which(floor(as.numeric(in_Perc))==10)[1] - 1
    num20 <- which(floor(as.numeric(in_Perc))==20)[1] - 1

    #----------------------------------
    pred_Data <- data_CUT[which(data_CUT$T== (Start_Training + tm + 1)),]
    #----------------------------------

    r_10 <- final_risk_Value[1:num10,]
    r_20 <- final_risk_Value[1:num20,]

    howm10 <- which(r_10[,1]%in%as.vector(pred_Data$gridID))

    howm20 <- which(r_20[,1]%in%as.vector(pred_Data$gridID))

    perc10 <- (length(howm10)/nrow(pred_Data))*100
    perc20 <- (length(howm20)/nrow(pred_Data))*100

    ########

    #-------------------------------------------
    #PREVIEW THE PREDICTIVE ACCURACY
    #
    ####################################################################

    #data to predict #note "data_CUT" has grid attached to it.



    #############################################################

    if(nrow(pred_Data)!=0){ #777777777777

      #----------------------------------------------tm <- 2
      #final_risk_Value
      #in_Perc
      #pred_Data

      pred_Data_1 <- as.vector(pred_Data[,13])
      pred_Data_2 <- as.vector(pred_Data[,14])


      #a<- c(0,2,3,4)
      #b<- matrix(2, 3, 1)
      #c <- matrix(1,1,1)

      a <- final_risk_Value
      b <- in_Perc
      c <- pred_Data_1
      d<- pred_Data_2

      comm <- list(a, b, c, d)

      this_Result[tm+1] <- list(comm)

    }##777777777777
    #############################################################this_Result <- NULL

    #############################################################
    if(nrow(pred_Data)==0){#333
      a <- 1111
      b <- 1111
      c <- 1111
      d <- 1111
      comm <- list(a, b, c, d)

      this_Result[tm+1] <- list(comm)

    }#333
    #############################################################

    if(nrow(pred_Data)==0){
      perc10 <- 111
      perc15 <- 111
    }


    flush.console()
    print(tm+1)
    print(Start_Training - back_in_TIME)
    print(paste("bandwidthXY=", round(bandWidthXY,digits=0), sep=" "))
    print(paste("nrows", nrow(dataPoints)))
    print(paste("Date predicted=",Start_Training + tm + 1))
    print(crime_types[kkk])
    print(perc10)
    print(perc20)
    print(paste(round(total_d,digits=0), "%"))
    print("-------------------------------")

    final_Risk <- rbind(final_Risk, cbind(perc10, perc20))

    b_final_Risk <- final_Risk

    cum_10Per <- b_final_Risk[,1]
    cum_20Per <- b_final_Risk[,2]

    rem <- which(cum_10Per==111)

    if(length(rem)==0){
      b_final_Risk <- b_final_Risk
    }

    if(length(rem)!=0){
      b_final_Risk <- b_final_Risk[-rem,]
    }

    b_final_Risk <- matrix(b_final_Risk,,2)

    flush.console()
    print("=======")
    print(paste(round(mean(b_final_Risk[,1]),digits=1), round(mean(b_final_Risk[,2]),digits=1), sep="  "))
    print(time.taken)
    print(time.taken2)
    print("=======")


    dev.off()


  }#500000000000000000000000000000000000000000000000##---------------------


  save(this_Result, file=paste("planar_KDE_SS_ensemble",crime_types[kkk],".RData",sep=""))


  newT <- unlist(collate_TIME2)

  TIME_COLLATE_TOGETHER <- cbind(TIME_COLLATE_TOGETHER, newT)



}##############0000000000000000000000000







timeO <- Chicago_Time_KDE <- TIME_COLLATE_TOGETHER
mean(timeO[,3])
sd(timeO[,3])

Chicago_Time_KDE_ASSAULT_MOTOR <- mean(TIME_COLLATE_TOGETHER[,2])






























REAL DATA

#import boundary data
spbdry <- readOGR(dsn = ".", "boundary_SS_UTM")  # boundary layer

library(stpp)

# Coerce all the data to data.frames for ggplot
W <- owin(poly = spbdry@polygons[[1]]@Polygons[[1]]@coords[seq(from = 3840, to = 1,
                                                               by = -1), ])
#
plot(W)
plot(sproads, col="grey", add=TRUE)


#import point data #head(real_Crime)
real_Crime <- read.table(file="chicago_2015_dataset.csv", sep=",", head=TRUE)
dat <- ppp(x = real_Crime$x, y = real_Crime$y, window = W)




ozon_tram1_14102011_14012012

library(gstat)
library(sp)
library(spacetime)
library(raster)
library(rgdal)
library(rgeos)

#####################################
The functions STIKhat and PCFhat of stpp package provide estimates of the STIK function and pair correlation function, respectively. The following code applies these estimators to the Chicago data under the assumption that the spatio-temporal intensity is separable. The spatial intensity is estimated using the function kernel2d of the package splancs. For the PCFhat the box kernel is used by default. Epanechnikov, Gaussian and biweight kernels can also be specified. The bandwidth value is obtained from the function dpik of the package KernSmooth (Wand 2013)

DATA_3d <- as.3dpoints(data_3d[, 1]/1000, data_3d[, 2]/1000, data_3d[,3])
#DATA_3d<-as.data.frame(DATA_3d)
Bound_area <- bound_area/1000

#Watch out! This might take up to 5 minutes
#Mt <- density(DATA_3d[, 3], n = 1000)
#mut <- Mt$y[findInterval(DATA_3d[, 3], Mt$x)] * dim(DATA_3d)[1]
#h <- mse2d(as.points(DATA_3d[, 1:2]), Bound_area, nsmse = 50, range = 4)
#h <- h$h[which.min(h$mse)]
#Ms <- kernel2d(as.points(DATA_3d[, 1:2]), Bound_area, h = h, nx = 5000, ny = 5000)
#atx <- findInterval(x = DATA_3d[, 1], vec = Ms$x)
#aty <- findInterval(x = DATA_3d[, 2], vec = Ms$y)
#mhat <- NULL

#adjust all the parameters here..
#for(i in 1:length(atx)) mhat <- c(mhat, Ms$z[atx[i], aty[i]])
#u <- seq(0, 10, by = 1)
#v <- seq(0, 15, by = 1)
#stik <- STIKhat(xyt = DATA_3d, s.region = Bound_area, t.region = c(1, 200),lambda = mhat * mut/dim(DATA_3d)[1], dist = u, times = v, #infectious = FALSE)
#g <- PCFhat(xyt = DATA_3d, lambda = mhat * mut/dim(DATA_3d)[1], dist = 1:20,times = 1:20, s.region = Bound_area, t.region = c(1, #200))

#plotK(stik)
#plotK(stik, persp = TRUE)
#plotPCF(g)
#plotPCF(g, persp = TRUE, theta = -65, phi = 35)



























spbdry <- readOGR(dsn = ".", "boundary_SS_UTM")  # boundary layer

sproads <- readOGR(dsn = ".", "utm_SS_shp")  # road layer

# Plot the data in ggplot
library(rgdal)
library(sp)

# Coerce all the data to data.frames for ggplot

W <- owin(poly = spbdry@polygons[[1]]@Polygons[[1]]@coords[seq(from = 3840, to = 1,
                                                               by = -1), ])
plot(W)

new_PP <- ppp(x = dat[, 1], y = dat[, 2], window = W)



# Now, create the ppp
xy <- coordinates(spcrime)
crime.ppp <- ppp(x = xy[, 1], y = xy[, 2], window = W)

plot(crime.ppp, pch=16, cex=1)

# Plot K function
plot(Gest(crime.ppp), r=200)

env <- envelope(Y = asthma.ppp, fun = Kest, nsim = 39)

plot(env)

#KERNEL PLOTS
#---------------------------------

k200 <- density(crime.ppp, sigma = 200)
SG <- as(k200, "SpatialGridDataFrame")
plot(SG)

colfunc<-colorRampPalette(c("red","yellow","green"))
plot(rep(1,50),col=(colfunc(50)), pch=19,cex=2)

plot(SG[4])


#nn
new_PP <- ppp(x = dat[, 1], y = dat[, 2], window = W) #aaa<-nndist(new_PP)..plot(ecdf(aaa),xlim=c(0,1000))
nns<-nndist(crime.ppp) #head(crime.ppp) nndist(fff)   <-crime.ppp[1:6] coordinates(names(new_dat <-cbind(fff$x, fff$y)) f
summary(nns)
plot(ecdf(nns))


> plot(ecdf(nns), xlim = c(0, 600))


> plot(Gest(crime.ppp), add = TRUE, lwd = 3)

> n <- drumlins_rr$n

> ex <- expression(runifpoint(n, win = rr))

> ex <- expression(runifpoint(n, win = rr))

> res <- envelope(crime.ppp, Gest, nsim = 99, simulate = ex, verbose = FALSE, saveall = TRUE)

> plot(res, xlim = c(0, 0.7))

> for (i in 2:100) lines(attr(res, "savedata")[[1]], attr(res, "savedata")[[i]], col = "grey")

> plot(res, add = TRUE, xlim = c(0, 0.7))


#  The data #drumlins_SP
coords.ppp <- ppp(x , y , xrange = c(0, 8) , yrange = c(0, 8) )

plot(coords.ppp)

#  Number of points
n <- coords.ppp$n

#  We want to generate completely spatially random point patterns to compare against the observed
ex <- expression(runifpoint(n , win = W))

#  Reproducible simulation
set.seed(1)

# Compute a simulation envelope using Gest, which estimates the nearest neighbour distance distribution function G(r)
res <- envelope(coords.ppp , Gest , nsim = 99, simulate = ex ,verbose = FALSE, savefuns = TRUE )

#  Plot
plot(res)



################################################
################################################

# inhomogeneous pattern of maples
X <- unmark(split(lansing)$maple)
plot(X)


# (1) intensity function estimated by model-fitting
# Fit spatial trend: polynomial in x and y coordinates






fit <- ppm(X, ~ polynom(x,y,2), Poisson())
# (a) predict intensity values at points themselves,
# obtaining a vector of lambda values
lambda <- predict(fit, locations=X, type="trend")

# inhomogeneous K function
Ki <- Kinhom(X, lambda)
plot(Ki)




# (b) predict intensity at all locations,
# obtaining a pixel image
lambda <- predict(fit, type="trend")
Ki <- Kinhom(X, lambda)
plot(Ki)


# (2) intensity function estimated by heavy smoothing
Ki <- Kinhom(X, sigma=0.1)
plot(Ki)


# (3) simulated data: known intensity function
lamfun <- function(x,y) { 50 + 100 * x }

# inhomogeneous Poisson process
Y <- rpoispp(lambda, 1000, W)

#---------------

# inhomogeneous Poisson process
Y <- rpoispp(lambda, 150, owin())




# inhomogeneous K function
Ki <- Kinhom(Y, lamfun)
plot(Ki)

# How to make simulation envelopes:
# Example shows method (2)
## Not run:

smo <- density.ppp(X, sigma=0.1)
Ken <- envelope(X, Kinhom, nsim=99,
                simulate=expression(rpoispp(smo)),
                sigma=0.1, correction="trans")
plot(Ken)























